# -*- coding: utf-8 -*-
"""GNB_practice.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1D9Qax6ipqC5gzFfhGT88mlAoJwiIb6QP

Como melhoria do trabalho fazem parte: a implementação do algoritmo de aprendizagem Naive Bayes e dos seus métodos.

# Importação de bibliotecas e tratamento de dados dos conjuntos
"""

from typing import Counter
import pandas as pd
import numpy as np
import math
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score

''' Tratamento de dados '''
#data = pd.read_csv('sample_data/entrega_antecipada.csv', skiprows=1)
#data = pd.read_csv('sample_data/entrega_antecipada.csv')
data_entrega_antecipada_with_id = pd.read_csv('sample_data/entrega_antecipada.csv')
data_entrega_antecipada = data_entrega_antecipada_with_id.drop('ID',axis=1) # 'ID' é o nome da coluna no ficheiro csv

data_iris = pd.read_csv('sample_data/iris.csv')

data_rice = pd.read_csv('sample_data/rice.csv')

''' Consulta e analise dos dados '''
print("DADOS RELATIVOS A DATA ENTREGA ANTECIPADA")
print("\n")
print(data_entrega_antecipada.head())
print(data_entrega_antecipada.info())
print(data_entrega_antecipada.describe())
print(data_entrega_antecipada.notnull().sum())
print(data_entrega_antecipada.isnull().sum())
print("\n")

print("DADOS RELATIVOS A DATA IRIS")
print("\n")
print(data_iris.head())
print(data_iris.info())
print(data_iris.describe())
print(data_iris.notnull().sum())
print(data_iris.isnull().sum())
print("\n")

print("DADOS RELATIVOS A DATA RICE")
print("\n")
print(data_rice.head())
print(data_rice.info())
print(data_rice.describe())
print(data_rice.notnull().sum())
print(data_rice.isnull().sum())
print("\n")

''' Separação dos conjuntos de dados '''
X_entrega_antecipada = data_entrega_antecipada.drop('class', axis=1)
y_entrega_antecipada = data_entrega_antecipada['class']

X_iris = data_iris.drop('class', axis=1)
y_iris = data_iris['class']

X_rice = data_rice.drop('class', axis=1)
y_rice = data_rice['class']

X_train, X_test, y_train, y_test = train_test_split(X_entrega_antecipada, y_entrega_antecipada, test_size=0.25, random_state=3)

X_train = np.array(X_train)
X_test = np.array(X_test)
y_train = np.array(y_train)
y_test = np.array(y_test)

"""# Implementação do **Algoritmo de Aprendizagem Naive Bayes(NB)**"""

def count_class(x, cond):
  ''' Conta o número de vezes que um elemento aparece em uma lista. '''
  count = 0
  for i in x:
      if(i == cond):
          count += 1
  return count

def gaussian_probability(x_val, feature_values, var_smoothing):
  ''' Calcula a probabilidade de um valor dado uma distribuição gaussiana. '''

  # Calcula média (μ) e devio padrão (σ)
  mean = sum(feature_values) / len(feature_values)
  variance = sum((x - mean) ** 2 for x in feature_values) / len(feature_values)

  # Adição da suavização para evitar variância zero
  sigma = math.sqrt(variance + var_smoothing)

  # return aplicação da formula Gaussiana: P(x) = (1 / (σ * √(2π))) * exp(-((x - μ)² / (2 * σ²)))
  return (1 / (sigma * math.sqrt(2 * math.pi))) * math.exp(-((x_val - mean) ** 2) / (2 * sigma ** 2))

# Implementação do algoritmo de aprendizagem Naive Bayes (NB)
class NBayesUE:
  ''' Implementação do algoritmo de aprendizagem Naive Bayes (NB). '''
  def __init__(self, var_smoothing=1e-9):
    self.var_smoothing = var_smoothing

  def fit(self, X, y):
    ''' Treina o modelo Naive Bayes (NB). '''
    self.X = X
    self.y = y

  def _predict(self, example):

    unique_class = list(set(self.y))
    class_probabilities = {}

    total_samples = len(self.y)

    for cls in unique_class:
      class_count = count_class(self.y, cls)
      prior = class_count / total_samples

      likelihood = 1.0

      class_indices = [i for i, val in enumerate(self.y) if val == cls]

      for feature_index in range(len(example)):
        feature_values_for_class = [self.X[i][feature_index] for i in class_indices]

        prob = gaussian_probability(example[feature_index], feature_values_for_class, self.var_smoothing)

        likelihood *= prob

      class_probabilities[cls] = prior * likelihood

    return max(class_probabilities, key=class_probabilities.get)

  def predict(self, example):
    ''' Faz a predição do modelo Naive Bayes (NB) para os dados de teste. '''
    if len(example.shape) == 1:
      return self._predict(example)

    predictions = []

    for i in range(len(example)):
      predictions.append(self._predict(example[i]))
    return predictions

  def score(self, X, y):
      ''' Calcula a exatidão do modelo.'''
      y_pred = self.predict(X)
      accuracy = np.sum(y_pred == y) / len(y)
      return accuracy

def score(self, X, y, sample_weight = None):
    ''' Calcula a acurácia do modelo Naive Bayes (NB) utilizando pesos. '''

    size_x = len(X)
    correct_predictions = 0.0
    total_weight = 0.0

    if sample_weight is not None:
      if len(sample_weight) != size_x:
        raise ValueError(f"sample_weight must have same length as x. Got {len(sample_weight)}, expected {size_x}.")
      weights = sample_weight
    else:
      weights = [1] * size_x

    unique_class = list(set(self.y))

    for i in range(size_x):
      try:

        weight = float(weights[i])
        total_weight += weight
        predicted = self._predict(X[i])
        atual = y[i]

        is_correct = predicted == atual

        if is_correct:
          correct_predictions += weight

      except Exception as e:
        print(f"Error predicting sample {i}: {e}.")

    if total_weight == 0:
      self.accuracy = 0.0
    else:
      self.accuracy = float(correct_predictions / total_weight)

    return self.accuracy

"""# Programa Modelos Naive Bayes"""

# Modelos Naive Bayes
def make_naive_bayes_models(X_train, X_test, y_train, y_test):
    '''Modelos Naive Bayes'''
    for var_smoothing_val in [1e-9, 1e-5]:
      print(f"Modelo Naive Bayes com var_smoothing={var_smoothing_val}")

      gnb = NBayesUE(var_smoothing = var_smoothing_val)
      gnb.fit(X_train, y_train)

      # Calcula a exatidão para o conjunto de treino com peso_amostra apropriado
      accuracy_train = gnb.score(X_train, y_train) #, sample_weight=[0.5 for i in range(len(X_train))])
      print('Exatidão no conjunto de treino:', accuracy_train)

      # Calcula a exatidao para o conjunto de teste com peso_amostra apropriado
      accuracy_test = gnb.score(X_test, y_test)#, sample_weight=[1 for i in range(len(X_test))])
      print('Exatidão no conjunto de teste:', accuracy_test)


# Conjuntos de dados
for (X,y) in [(X_entrega_antecipada, y_entrega_antecipada),(X_iris,y_iris),(X_rice,y_rice)]:
    print(f"Conjunto de dados: {X.columns.values}")

    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=3)

    X_train = np.array(X_train)
    X_test = np.array(X_test)
    y_train = np.array(y_train)
    y_test = np.array(y_test)

    make_naive_bayes_models(X_train, X_test, y_train, y_test)
    print()
    print()
    print()